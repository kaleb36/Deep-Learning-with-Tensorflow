{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b625a6-56a3-4225-b8bc-2e4bcd4d63b2",
   "metadata": {},
   "source": [
    "# Run this code on Linux environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9857d40-275f-4c55-b8e8-25b652768d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 15:43:52.656195: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-25 15:43:54.110522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 15:44:00.059759: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-25 15:44:00.194712: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    \"cats_vs_dogs_small//train\",\n",
    "    image_size=(180,180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    \"cats_vs_dogs_small//validation\",\n",
    "    image_size=(180,180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    \"cats_vs_dogs_small//test\",\n",
    "    image_size=(180,180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fda2424-07bd-4a01-a36d-1c1c9fb08a58",
   "metadata": {},
   "source": [
    "# augmentation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdcb1c2d-f3f8-4756-bc68-cd8666d707d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "]\n",
    "\n",
    "\n",
    "def data_augmentation(x):\n",
    "    for layer in augmentation_layers:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edb601f-3552-4063-973a-b5b0ddc694fe",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0aa9111-efba-4a84-a622-413e77c310e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_2 (InputLayer)        [(None, 180, 180, 3)]     0         Y          \n",
      "                                                                            \n",
      " rescaling (Rescaling)       (None, 180, 180, 3)       0         Y          \n",
      "                                                                            \n",
      " xception (Functional)       (None, 6, 6, 2048)        20861480  N          \n",
      "                                                                            \n",
      " global_average_pooling2d (G  (None, 2048)             0         Y          \n",
      " lobalAveragePooling2D)                                                     \n",
      "                                                                            \n",
      " dropout (Dropout)           (None, 2048)              0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 1)                 2049      Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 20,861,480\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(180, 180, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "\n",
    "# Pre-trained Xception weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "x = scale_layer(inputs)\n",
    "\n",
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd1956-dffe-411b-ab9d-2f89853d58b9",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "967908b4-e12e-42e0-b930-c0bdae894157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the top layer of the model\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 15:44:29.566186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [2000]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-01-25 15:44:29.567239: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_18' with dtype resource\n",
      "\t [[{{node Placeholder/_18}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 0s - loss: 0.2260 - binary_accuracy: 0.9210"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 15:45:23.202476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [1000]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-01-25 15:45:23.202900: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1000]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 80s 1s/step - loss: 0.2260 - binary_accuracy: 0.9210 - val_loss: 0.0795 - val_binary_accuracy: 0.9750\n",
      "Epoch 2/4\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.0952 - binary_accuracy: 0.9710 - val_loss: 0.0592 - val_binary_accuracy: 0.9810\n",
      "Epoch 3/4\n",
      "63/63 [==============================] - 77s 1s/step - loss: 0.0815 - binary_accuracy: 0.9735 - val_loss: 0.0515 - val_binary_accuracy: 0.9800\n",
      "Epoch 4/4\n",
      "63/63 [==============================] - 82s 1s/step - loss: 0.0806 - binary_accuracy: 0.9695 - val_loss: 0.0500 - val_binary_accuracy: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7eff79344ac0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 4\n",
    "print(\"Fitting the top layer of the model\")\n",
    "model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5115d1bc-8d4e-4857-b200-892b690b18e8",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b088d-bfda-461a-bd7a-9a7a8dc70aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_2 (InputLayer)        [(None, 180, 180, 3)]     0         Y          \n",
      "                                                                            \n",
      " rescaling (Rescaling)       (None, 180, 180, 3)       0         Y          \n",
      "                                                                            \n",
      " xception (Functional)       (None, 6, 6, 2048)        20861480  Y          \n",
      "                                                                            \n",
      " global_average_pooling2d (G  (None, 2048)             0         Y          \n",
      " lobalAveragePooling2D)                                                     \n",
      "                                                                            \n",
      " dropout (Dropout)           (None, 2048)              0         Y          \n",
      "                                                                            \n",
      " dense (Dense)               (None, 1)                 2049      Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "____________________________________________________________________________\n",
      "Fitting the end-to-end model\n",
      "Epoch 1/4\n",
      "19/63 [========>.....................] - ETA: 3:11 - loss: 0.0663 - binary_accuracy: 0.9770"
     ]
    }
   ],
   "source": [
    "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "# since we passed `training=False` when calling it. This means that\n",
    "# the batchnorm layers will not update their batch statistics.\n",
    "# This prevents the batchnorm layers from undoing all the training\n",
    "# we've done so far.\n",
    "base_model.trainable = True\n",
    "model.summary(show_trainable=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 4\n",
    "print(\"Fitting the end-to-end model\")\n",
    "model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc16aa-ff51-408d-a6f7-bfe28c065ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaltf",
   "language": "python",
   "name": "kaltf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
